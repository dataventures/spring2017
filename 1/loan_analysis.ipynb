{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Dataframe Exploration - Lending Club\n",
    "\n",
    "Now, let's try and use the Pandas' Dataframe structure to analyze a dataset from the Lending Club. The [Lending Club](https://www.lendingclub.com/) is a peer-to-peer lending site where members make loans to each other. For this exercise, we'll be using a public dataset that is generously hosted by Spark. This notebook can be downloaded (with associated data) from its repo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "Any good statistical analysis should start with a fundamental question. Since we are working with a dataset of loans, what interesting questions would we like the answer to? Some options include:\n",
    "\n",
    "* How likely a loan is to default?\n",
    "* How is the interest rate of a loan computed from the various loan variables?\n",
    "* How likely is an individual, with certain attributes, to get his/her loan approved?\n",
    "\n",
    "While these are all interesting questions, they are fundamentally different and so require different approaches. Today we will explore the second question further and investigate how the interest rate of a loan can be estimated by various different factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "So we want to explore these data, and try to gain some insights into what might be useful in creating a linear regression model. Most importantly, we want to try and separate out \"the noise\". To do so, we follow the following steps:\n",
    "\n",
    "* Browse the data\n",
    "* Data cleanup\n",
    "* Visual exploration\n",
    "* Model derivation\n",
    "\n",
    "These steps are universal to quality Data Science analysis and should be used for nearly every dataset. Today we will trace through the entire data analysis process so that you have a solid backbone on which you can implement the more advanced models you'll soon learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Browse the Data\n",
    "Let us try and understand the data first. We have a long list of variables:\n",
    "\n",
    "* Amount.Requested - numeric. The amount (in dollars) requested in the loan application.\n",
    "* Amount.Funded.By.Investors - numeric. The amount (in dollars) loaned to the individual.\n",
    "* Interest.rate – character. The lending interest rate charged to the borrower.\n",
    "* Loan.length - character. The length of time (in months) of the loan.\n",
    "* Loan.Purpose – categorical variable. The purpose of the loan as stated by the applicant.\n",
    "* Debt.to.Income.Ratio – character The % of consumer’s gross income going toward paying debts.\n",
    "* State - character. The abbreviation for the U.S. state of residence of the loan applicant.\n",
    "* Home.ownership - character. Indicates whether the applicant owns, rents, or has a mortgage.\n",
    "* Monthly.income - categorical. The monthly income of the applicant (in dollars).\n",
    "* FICO.range – categorical (expressed as a string label e.g. “650-655”). A range indicating the applicants FICO score.\n",
    "* Open.CREDIT.Lines - numeric. The number of open lines of credit at the time of application.\n",
    "* Revolving.CREDIT.Balance - numeric. The total amount outstanding all lines of credit.\n",
    "* Inquiries.in.the.Last.6.Months - numeric. Number of credit inquiries in the previous 6 months.\n",
    "* Employment.Length - character. Length of time employed at current job.\n",
    "\n",
    "Which variable are we really looking to try to understand?\n",
    "\n",
    "    Interest.rate – character. The lending interest rate charged to the borrower.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup\n",
    "\n",
    "But before we can do anything more, we need to process our data and make sure that it is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# first we ingest the data from the source on the web\n",
    "# this contains a reduced version of the data set from Lending Club\n",
    "import pandas as pd\n",
    "loansData = pd.read_csv('https://spark-public.s3.amazonaws.com/dataanalysis/loansData.csv')\n",
    "loansData['Interest.Rate'][0:5] # first five rows of Interest.Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loansData['Loan.Length'][0:5] # first five rows of Loan.Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loansData['FICO.Range'][0:5] # first five rows of FICO.Range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise One**\n",
    "\n",
    "Now that we have an idea of the types of data in loansData we can compute some metrics on the data to start discovering interesting trends. For example, you can sort the data and print out the 5 highest interest rates. Using methods from [the Pandas documentation](http://pandas-docs.github.io/pandas-docs-travis/10min.html), compute five interesting trends in the data. This is an exercise in creatively deciding which aspects of the data might provide insights. One such trend is given as an example - the 5 largest loan amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insight 1\n",
    "loansData.sort_values(by='Amount.Requested', ascending=False)[0:5]\n",
    "\n",
    "# insight 2\n",
    "\n",
    "# insight 3\n",
    "\n",
    "# insight 4\n",
    "\n",
    "# insight 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about this data? It seems to be complete, which is good, but it still can't be processed by an algorithm yet.\n",
    "\n",
    "We see here that:\n",
    "* the interest rate information has \"%\" symbols in it.\n",
    "* loan length has \" months\" in it\n",
    "\n",
    "**Exercise Two**: See if you can find the following errors in the data:\n",
    "* there are a couple of values that are so large they must be typos\n",
    "* some values are missing \"NA\" values i.e. not available.\n",
    "* the FICO Range is really a numeric entity but is represented as a categorical variable in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## To-do: Exercise Two\n",
    "\n",
    "\"\"\"\n",
    "Print out one data entry for each of the following errors:\n",
    "1) Outlier values\n",
    "2) Entries with \"NA\" values\n",
    "3) Incorrect data types\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FICO Range is represented as a categorical variable in the data.\n",
    "\n",
    "We need to change the categorical variable for FICO Range into something numeric so that we can use it in our calculations. As it stands, the values are merely labels, and while they convey meaning to humans, our software can't interpret them as the numbers they really represent.\n",
    "\n",
    "So as a first step, we convert them from categorical variables to strings. So the abstract entity 735-739 becomes a string \"735-739\". Then we parse the strings so that a range such as \"735-739\" gets split into two numbers (735,739).\n",
    "Finally we pick a single number to represent this range. We could choose a midpoint but since the ranges are narrow we can get away with choosing one of the endpoints as a representative. Here we arbitrarily pick the lower limit and with some imperious hand waving, assert that it is not going to make a major difference to the outcome.\n",
    "In a further flourish of imperiousness we could declare that \"the proof is left as an exercise to the reader\". But in reality there is really no such formal \"proof\" other than trying it out in different ways and convincing oneself. If we wanted to be mathematically conservative we could take the midpoint of the range as a representative and this would satisfy most pointy-haired mathematician bosses that \"Data Science Dilbert\" might encounter.\n",
    "\n",
    "To summarize - cleaning our data involves:\n",
    "* removing % signs from rates\n",
    "* removing the word ” months\" from loan length.\n",
    "* managing outliers - remove such rows in this case\n",
    "* managing NA - remove such rows in this case\n",
    "\n",
    "*Notes:*\n",
    "* There is one especially high outlier with monthly income > 100K+.This is likely to be a typo and is removed as a data item.\n",
    "* There is also one data item with all N/A - this is also removed.\n",
    "\n",
    "**Exercise Three**: Perform each of the above manipulations on the dataset:\n",
    "* import the data\n",
    "* remove the '%' suffix from each row\n",
    "* remove the ' months' suffix from each row\n",
    "* remove the outlier rows\n",
    "* remove rows with NA\n",
    "\n",
    "Hint: the [apply method](http://pandas-docs.github.io/pandas-docs-travis/10min.html#apply) is very helpful for operations like this, where we are applying functions to map each entry in a column to a corresponding value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To-do: Exercise Three\n",
    "\n",
    "# import the data\n",
    "\n",
    "# remove the '%' suffix from each row\n",
    "\n",
    "# remove the ' months' suffix from each row\n",
    "\n",
    "# remove the outlier rows\n",
    "\n",
    "# remove rows with NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Note on Resources**\n",
    "\n",
    "We've shown some ways to operate on Dataframes to extract useful information. Of course, these methods like apply, sort, and filter are only scratching the surface of what Pandas has to offer. You'll find that for different types of datasets and analysis, you might need methods for aggregation, data reshaping, time series analysis, and much more. Luckily, there is extensive documentation for Pandas (and most Python libraries that we'll be using, for that matter). We plan to give you a solid background on how to apply these tools in the data science framework, but it's up to you to dig deeper into exactly what each tool has to offer! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Exploration\n",
    "\n",
    "Now we are going to follow a standard set of steps in exploring data. We apply the following simple visualizations. This is something we will typically also do for other data sets we encounter in other explorations.\n",
    "\n",
    "### Histogram\n",
    "\n",
    "A histogram shows us the shape of the distribution of values for a single variable. On the x-axis we have the variable under question, divided into buckets or bins. This is a key feature of a histogram.\n",
    "\n",
    "The bin size is adjustable and different bin sizes give different information. A large bin size gives us an idea of the coarser grained structure of the distribution while a smaller bin size will shine light on the finer details of the distribution. In either case we can compare distributions, or quickly identify some key hints that tell use how best to proceed.\n",
    "\n",
    "With the distribution of FICO scores we see the histogram below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.figure()\n",
    "loansmin = pd.read_csv('loanf.csv')\n",
    "fico = loansmin['FICO.Score']\n",
    "p = fico.hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are we looking at the FICO score? Because we know from domain knowledge that this is the primary determinant of interest rate.\n",
    "The histogram shows us that the distribution is not a normal or gaussian distribution but that there are some other factors that might be affecting or distorting the shape of the distribution away from the bell curve. We want to dig a little deeper.\n",
    "\n",
    "### Box Plot\n",
    "\n",
    "Next we take a box plot which allows us to quickly look at the distribution of interest rates based on each FICO score range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.figure()\n",
    "loansmin = pd.read_csv('loanf.csv')\n",
    "\n",
    "p = loansmin.boxplot('Interest.Rate','FICO.Score')\n",
    "q = p.set_xticklabels(['640','','','','660','','','','680','','','','700',\n",
    "  '720','','','','740','','','','760','','','','780','','','','800','','','','820','','','','840'])\n",
    "\n",
    "q0 = p.set_xlabel('FICO Score')\n",
    "q1 = p.set_ylabel('Interest Rate %')\n",
    "q2 = p.set_title('                          ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, this tells us that there is a general downward trend in interest rate for higher FICO scores. But, given the same range of FICO scores we see a range of interest rates, not a single value - so it appears there are other factors determining interest rate, given a fixed FICO score range. We still need to investigate the impact of these other factors and quantify their impact.\n",
    "\n",
    "So, what might these other factors be?\n",
    "\n",
    "**Exercise Four**: repeat what we did above, creating a histogram and box plot for 2 additional factors that you think might contribute to variations in interest rate, and give 2 sentences for each factor explaining the results you find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## To-do: Exercise Four"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, repeating this process for each factor we're interested in is tedious and doesn't fully capture the relationship between different factors. A great way to look at multiple factors simultaneously is the scatterplot matrix.\n",
    "\n",
    "### Scatterplot Matrix\n",
    "\n",
    "A scatter-what???\n",
    "\n",
    "The scatterplot matrix is a grid of plots of multiple variables against each other. It shows the relationship of each variable to the others. The ones on the diagonal don't fit this pattern. Why not? What does it mean to find the relationship of something to itself, in this context. Not much, since we are trying to determine the impact of some variable on another variable.\n",
    "We're going to look at a scatterplot matrix of the five variables in our data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TRY THIS!\n",
    "import pandas as pd\n",
    "loansmin = pd.read_csv('loanf.csv')\n",
    "a = pd.scatter_matrix(loansmin,alpha=0.05,figsize=(10,10), diagonal='hist')\n",
    "## Click on the line above\n",
    "## Change 'hist' to 'kde' then hit shift-enter, with the cursor still in this box\n",
    "## The plot will redraw - it takes a while. While it is recomputing you will see a \n",
    "## message-box that says 'Kernel Busy' near the top right corner\n",
    "## You can change the code and hit shift-enter to re-execute the code\n",
    "## Try changing the (10,10) to (8,8) and (12,12)\n",
    "## Try changing the alpha value from 0.05 to 0.5 \n",
    "## How does this change in alpha change your ability to interpret the data?\n",
    "## Feel free to try other variations. \n",
    "## If at any time you scramble the code and forget the syntax \n",
    "## a copy of the original code is below. Copy and paste it in place. \n",
    "## Remember to remove the hashmarks.\n",
    "## a = pd.scatter_matrix(loansmin, alpha=0.05,figsize=(10,10), diagonal='hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this diagram, the boxes on the diagonal contain histogram plots of the respective variable itself.\n",
    "\n",
    "So if the 3rd variable is Loan Amount then the third row and third column contain the Loan Amount. The third element down the diagonal would then be the histogram of the Loan Amount. To see how the Loan Amount (3rd) affects the Interest Rate (1st) then we look for the intersection of the 3rd row and the 1st column. We also notice that we could have looked for the intersection of the 3rd column and 1st row. Indeed, they will always have the same plot because the scatterplot matrix plot is symmetric about the diagonal.\n",
    "\n",
    "When there is a significant, useful effect between two variables we will see a noticeable trend in the scatterplot at the intersection. Where there is no or little effect, we will see no noticeable trend.\n",
    "\n",
    "Let's compare two plots: the intersection of the 1st row and the 2nd column, and the intersection of the 1st row and the 4th column. In the first, FICO score shows an approximate but unmistakeable linear trend. In the second, Monthly Income shows no impact as we move along the x-axis. All the dots are bunched up near one end but show no clear, linear trend like the first one. Similarly, there is no obvious variation in the plot for Loan Length while there is a distinct but increasing trend present in the plot for Loan Amount.\n",
    "\n",
    "So what does this suggest? It suggests that we should use FICO and Loan Amount in our model as independent variables, while Monthly Income and Loan Length don't seem to be too useful and should be ignored in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## To-do: Bonus Exercise\n",
    "\"\"\"\n",
    "Now that you've completed browsing, cleaning and visualising the data, it's time to build a model. \n",
    "Using any model of your choice and keeping in mind what we have learnt about the data so far, build\n",
    "a model using the SKLearn library.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
